{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b225207",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- 정량 평가의 경우 (e.g. acc 80% 이상)은 정확히 해당 지표를 맞추어야 합니다.\n",
    "- 다음의 경우는 **미평가**가 될 수 있습니다.\n",
    "    - **코드만 있고 결과물이 없는 경우**\n",
    "        - **코드에 대한 설명이 없는 경우**\n",
    "        - **회고가 없는 경우**\n",
    "    - **깃헙 링크가 잘못되어 열람이 안되는 경우**\n",
    "        - **(중요) 링크를 제출하기 전에 해당 링크에서 프로젝트가 잘 열리는지 꼭 확인해주세요.**\n",
    "        - 만약 프로젝트의 용량이 커서 프로젝트 로딩이 안된다면 **nbviewer 링크**를 제출해주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd332872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# sklearn라이브러리를 임포트하고 버전 확인하기\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f24c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import 하기\n",
    "from sklearn.datasets import load_breast_cancer         # sklearn datasets으로 breast_cancer 데이터셋 로드\n",
    "from sklearn.model_selection import train_test_split    # 데이터셋을 train, test로 분할\n",
    "\n",
    "from sklearn.metrics import classification_report       # Text summary of the precision, recall, F1 score for each class\n",
    "from sklearn.metrics import accuracy_score              # sklearn.metrincs는 평가에 대한 함수 모음집, 정확도\n",
    "from sklearn.metrics import confusion_matrix            # sklearn.metrincs는 평가에 대한 함수 모음집, 오차행렬\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier         # DecisionTree 분류기\n",
    "from sklearn.ensemble import RandomForestClassifier     # Random forest 분류기\n",
    "from sklearn import svm                                 # SVM 분류기\n",
    "from sklearn.linear_model import SGDClassifier          # SGD 분류기\n",
    "from sklearn.linear_model import LogisticRegression     # Logistic Regression 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a63047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((114, 30), (114,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 데이터 준비하기\n",
    "breast_cancers = load_breast_cancer()               # breast_cancer 데이터셋의 객체 생성(자료 가져오기)\n",
    "type(breast_cancers)                                # type은 Bunch으로 Dictionary 자료형과 유사한 자료형\n",
    "\n",
    "\n",
    "# 3. 데이터 이해하기\n",
    "\n",
    "# 데이터와 타켓 데이터셋 변수에 할당 \n",
    "breast_cancers_data = breast_cancers.data           # breast_cancer 데이터셋의 feature 값들을 data 변수에 할당\n",
    "breast_cancers_label = breast_cancers.target        # breast_cancer 데이터셋의 target 값들을 label 변수에 할당\n",
    "\n",
    "# breast_cancers 메서드 확인하기\n",
    "dir(breast_cancers)                                 # breast_cancers 메서드 보기\n",
    "breast_cancers.keys()                               # breast_cancers 메서드 보기 (딕셔너리 형태)\n",
    "\n",
    "# 데이터\n",
    "breast_cancers_data                                 # breast_cancers 데이터셋의 각 데이터(행)을 보기\n",
    "                                                    # type은 ndarray(1차원)\n",
    "                                                    # data는 머신러닝에 학습시킬 \"문제지\" \n",
    "breast_cancers_data.shape                           # nd.ndarray 타입이고, 569개 데이터(세로)가 있으며 30개의 속성값(가로)이 있음\n",
    "breast_cancers_data[0]                              # breast_cancers.data의 첫번째 데이터(원소) 확인\n",
    "breast_cancers_data[0].shape                        # 첫번째 데이터는 30개 속성이 있음\n",
    "\n",
    "# 속성 \n",
    "breast_cancers.feature_names                        # 속성(Attribute)의 이름\n",
    " \n",
    "# Label, Class, Target\n",
    "breast_cancers.target                               # breast_cancers 데이터셋의 속성값(열) 보기.\n",
    "                                                    # type은 ndarray(1차원)\n",
    "                                                    # target은 머신러닝 학습에 필요한 \"정답지\"\n",
    "breast_cancers.target.shape                         # target 속성은 569개 데이터가 존재\n",
    "breast_cancers.target_names                         # label 또는 Class 또는 Target 이름\n",
    "target_names = breast_cancers.target_names          # target_names 변수에 할당\n",
    "\n",
    "# 요약 문서 \n",
    "print(breast_cancers.DESCR)                         # breast_cancers 데이터셋 설명\n",
    "\n",
    "breast_cancers.frame                                # ???? NoneType이며\n",
    "\n",
    "\n",
    "# 4. Train, Test로 데이터 분할하기\n",
    "''' 전체 데이터를 모두 학습시키는데 사용하면 테스트용 데이터가 없으므로 데이터의 일부는 테스트용으로 떼어놓는다\n",
    "    breast_cancers_data 데이터셋을 X_train, X_test(20%) 떼어두고, breast_cancers_label 데이터셋을 y_train, y_test(20%) 떼어 놓는다\n",
    "    \n",
    "    테스트 사이즈 0.2라는 의미는 20%를 떼어 놓겠다는 의미\n",
    "    \n",
    "    random_state는 데이터 분할하기 전에 임의로 돌려서 분할한다는 의미이며 숫자는 램덤 시드값.\n",
    "    train_test_split 인자중 shuffle=True이므로 랜덤 씨드값만 부여하면 됨\n",
    "    사용 이유는 wines.target의 값은 0으로 채우다가 1채우고 2채우는 형식이기 때문에\n",
    "    먄약 랜덤으로 썩지 않고 데이터를 분할하면 앞에서부터 대부분 0과 1의 라벨값만 얻어지고 테스트는 전부 2로 할당받을 것이므로 \n",
    "    데이터 결과의 정확성을 위해 임의로 썩는다\n",
    "    '''\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancers_data, breast_cancers_label, test_size=0.2, random_state=7)  \n",
    "\n",
    "X_train.shape, y_train.shape                     # train 데이터는 전체 데이터의 80% 차지\n",
    "X_test.shape, y_test.shape                       # test 데이터는 전체 데이터의 20% 차지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b4f0c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names                                       # 타켓 네임 출력해보기. 악성과 양성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61877b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d08438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-1. DecisionTree 모델 학습\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)     # DecisionTreeClassifier 객체 생성, 랜덤 씨드는 32\n",
    "print(decision_tree._estimator_type)                        # decision_tree 객체 타입은 classifier인 분류기\n",
    "\n",
    "decision_tree.fit(X_train, y_train)                         # train 데이터셋으로 의사결정나무 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)        # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76c1896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-2. Random Forest 모델 학습\n",
    "random_forest = RandomForestClassifier(random_state=32)  # Random Forest Classifier 객체 생성\n",
    "print(random_forest._estimator_type)                     # random_forest 객체 타입은 classifier인 분류기\n",
    "\n",
    "random_forest.fit(X_train, y_train)                      # train 데이터셋으로 랜덤 포레스트 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_random_forest = random_forest.predict(X_test)     # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5165c01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-3. SVM 모델 학습\n",
    "svm_model = svm.SVC()                                    # SVM Classifier 객체 생성\n",
    "print(svm_model._estimator_type)                         # svm_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "\n",
    "svm_model.fit(X_train, y_train)                          # train 데이터셋으로 svm 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_svm_model = svm_model.predict(X_test)             # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_svm_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06545717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-4. SGD Classifier 모델 학습\n",
    "sgd_model = SGDClassifier()                              # SGD Classifier 객체 생성\n",
    "print(sgd_model._estimator_type)                         # sgd_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "sgd_model.fit(X_train, y_train)                          # train 데이터셋으로 sgd 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)             # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_sgd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51e3b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-5. Logistic Regression 모델 학습\n",
    "logistic_model = LogisticRegression(max_iter=10000)      # Logistic Regression 객체 생성\n",
    "print(logistic_model._estimator_type)                    # logistic_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "logistic_model.fit(X_train, y_train)                     # train 데이터셋으로 logistic regression 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)   # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 분류에 사용되는 척도 종류 및 성능 평가\n",
    "# 척도 종류\n",
    "#    1) accuracy_score\n",
    "#    2) confusion matrix\n",
    "#    3) classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ba5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-1 DecisionTree 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c73f64c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 91%이므로 높은 값이다. 테스트 데이터가 약 114개이므로 총 104개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1678ad1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  7],\n",
       "       [ 3, 71]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_decision_tree)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 91%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 40개중 실제 malignant을 보여주고 올바르게 malignant이라고 예측한 경우(TP)가 33개,\n",
    "#             실제 malignant을 보여줬는데 예측 benign으로 예측한 경우(FN) 7개 -> 82%\n",
    "# 실제 클래스 1: 총 74개중 실제 benign을 보여주고 올바르게 benign이라고 예측한 경우(TP)가 71개,\n",
    "#             실제 benign을 보여줬는데 malignant으로 예측한 경우(FN) 3개 -> 96%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 36개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 33 -> 92%\n",
    "# 예측 클래스 1: 총 78개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 71 -> 91%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 0.90와 0.91로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c884384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.82      0.87        40\n",
      "      benign       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-1-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_decision_tree, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-2. Random Forest 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5411670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-2-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 100%이므로 높은 값이다. 테스트 데이터가 약 114개이므로 총 114개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44e82117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-2-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_random_forest)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 100%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이라 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 40개중 실제 malignant을 보여주고 올바르게 malignant이라고 예측한 경우(TP)가 40개 -> 100%\n",
    "# 실제 클래스 1: 총 74개중 실제 benign을 보여주고 올바르게 benign이라고 예측한 경우(TP)가 74개 -> 100%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 40개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 40 -> 100%\n",
    "# 예측 클래스 1: 총 74개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 74 -> 100%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 1.00와 1.00로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18cc3c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00        40\n",
      "      benign       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-2-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_random_forest, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-3. SVM 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffcec3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035087719298246"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-3-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 90%이므로 높은 값이다. 테스트 데이터가 약 114개이므로 총 103개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85d4fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29, 11],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-3-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_svm_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 90%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 40개중 실제 malignant을 보여주고 올바르게 malignant이라고 예측한 경우(TP)가 29개,\n",
    "#             실제 malignant을 보여줬는데 예측 benign으로 예측한 경우(FN) 11개 -> 72%\n",
    "# 실제 클래스 1: 총 74개중 실제 benign을 보여주고 올바르게 benign이라고 예측한 경우(TP)가 74개, -> 100%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 29개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 29 -> 100%\n",
    "# 예측 클래스 1: 총 85개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 74 -> 87%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 0.89와 0.90로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21ff289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.72      0.84        40\n",
      "      benign       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-3-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_svm_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d22fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-4. SGD Classifier 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a95e3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771929824561403"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-4-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_sgd_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 88%이므로 나쁘지 않다. 테스트 데이터가 약 114개이므로 총 61.6개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "716bf669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  5],\n",
       "       [ 9, 65]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-4-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_sgd_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 87.7%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 40개중 실제 malignant을 보여주고 올바르게 malignant이라고 예측한 경우(TP)가 35개,\n",
    "#             실제 malignant을 보여줬는데 예측 benign으로 예측한 경우(FN) 5개 -> 88%\n",
    "# 실제 클래스 1: 총 74개중 실제 benign을 보여주고 올바르게 benign이라고 예측한 경우(TP)가 65개,\n",
    "#             실제 malignant을 보여줬는데 예측 benign으로 예측한 경우(FN) 9개 -> 88%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 44개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 35 -> 80%\n",
    "# 예측 클래스 1: 총 70개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 65 -> 93%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 0.87와 0.88로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e1bdf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.80      0.88      0.83        40\n",
      "      benign       0.93      0.88      0.90        74\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-4-3 classification_reprot 평가\n",
    "print(classification_report(y_test, y_pred_sgd_model, target_names=target_names, zero_division=0))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-5. Logistic Regression 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6455b8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-5-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 94.7%이므로 나쁘지 않다. 테스트 데이터가 약 114개이므로 총 108개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7675b1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  6],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-5-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_logistic_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 94.7%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 40개중 실제 malignant을 보여주고 올바르게 malignant이라고 예측한 경우(TP)가 34개,\n",
    "#             실제 malignant을 보여줬는데 예측 benign으로 예측한 경우(FN) 6개 -> 85%\n",
    "# 실제 클래스 1: 총 74개중 실제 benign을 보여주고 올바르게 benign이라고 예측한 경우(TP)가 74개,\n",
    "#             실제 malignant을 보여줬는데 예측 benign으로 예측한 경우(FN) 6개 -> 100%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 34개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 34 -> 100%\n",
    "# 예측 클래스 1: 총 80개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 74 -> 93%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 0.94와 0.95로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2cf1ade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.85      0.92        40\n",
      "      benign       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-5-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_logistic_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76367c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "최종 결과 해석\n",
    "# 어떤 모델이 가장 좋은 성능을 보이는가? \n",
    "# -> Random Forest 모델\n",
    "# 모델 성능 평가 지표로 무엇으로 설정하겠는가?\n",
    "# -> Random Forest 모델의 평가가 정확도가 높고 데이터셋의 각 클래스마다 데이터들이 balanced하다. 따라서 정확도만으로도 평가해도 좋지만 추가적으로 오차행렬을\n",
    "#    진행했는데 그중에서 F1-Score 점수가 1.00으로 다른 모델에 비해 가장 높았으므로 최종 모델을 Random Forest으로 선정함\n",
    "# -> 블로그나 유튜브에서는 이진 분류인 경우 로지스틱 회귀를 많이 사용한다고 했습니다. 여기서 모델 성능 평가를 해보니 Random Forest의 점수가 더 높에 나와서\n",
    "#    Random Forest로 선정하였습니다\n",
    "# sklearn.metrics에서 제공하는 평가지표 선정하고 선택한 이유?\n",
    "# -> classification_report와 confusion_matrix을 선택했고, 그 이유는 오차행렬을 알면 정확도, 재현율, 정밀도, 가중조화평균, 단순평균, 가중평균을 구할 수 있기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b11109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회고\n",
    "\n",
    "'''\n",
    "1. 이번 프로젝트에서 어려웠던 점\n",
    "   이번 프로젝트도 앞의 버전과 거의 비슷했다. 다만, 해석하는 방법과 해석 이해도가 낮아서 제대로 해석했는지에 대한 확신이 없다\n",
    "    \n",
    "2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "    해석에 대한 확신이 없음\n",
    "    \n",
    "3. 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "   1) breast_cancer 데이터셋의 관련 메서드를 모두 출력해보고 속성과 타켓/클래스 이름 등 각각이 무엇을 의미하는지 확인해보았습니다.\n",
    "      feature은 총 30개며 클래스는 malignant와 benign 총 2가지가 있었습니다\n",
    "   2) 5가지 모델에 전부 학습 시키고 그 결과를 비교하여 최종 모델을 선정하였습니다\n",
    "   3) 평가 지표 선택 이유와 그 근거를 위에 기술함\n",
    "    \n",
    "4. 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정\n",
    "    이번 평가에는 루브릭 평가가 없었음\n",
    "    \n",
    "5. 자기 다짐\n",
    "    같은 내용이지만 해석을 하는 방법을 더 정확히 알아야겠다는 생각이 든다\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e18c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273c9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea6635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
